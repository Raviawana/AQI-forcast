{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & configuration\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn utils\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Regressors\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Optional boosters (wrapped in try/except to not break if libs missing)\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except Exception:\n",
    "    XGBRegressor = None\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "except Exception:\n",
    "    LGBMRegressor = None\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "except Exception:\n",
    "    CatBoostRegressor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/ravigurjar/Desktop/temp/sample/dessertation/data/cleaned/final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded. Assets path: ../asset/prediction\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Local config (change if you want)\n",
    "TARGET_COL = \"aqi_value\"\n",
    "ASSETS_PATH = \"../asset/prediction\"\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n",
    "USE_IMPUTATION = False  \n",
    "TIME_COL_NAMES = {\"date\", \"timestamp\", \"datetime\"}\n",
    "KFOLD_SPLITS = 5\n",
    "PERM_N_REPEATS = 10\n",
    "\n",
    "\n",
    "os.makedirs(ASSETS_PATH, exist_ok=True)\n",
    "print(\"Config loaded. Assets path:\", ASSETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df found with rows: 7835 columns: 13\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Basic checks (assumes a DataFrame named `df` already exists in the notebook)\n",
    "if 'df' not in globals():\n",
    "    raise RuntimeError(\"DataFrame 'df' not found. Load your dataset into variable `df` before running further cells.\")\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise KeyError(f\"Target column '{TARGET_COL}' not found. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "print(\"df found with rows:\", len(df), \"columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected numeric features (count): 11\n",
      "['latitude', 'longitude', 'pm25_ugm3', 'co_ppm', 'no2_ppb', 'so2_ppb', 'o3_ppb', 'temperature_c', 'relative_humidity', 'wind_speed_ms', 'wind_direction_deg']\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Feature selection (numeric) and leakage exclusion\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "features = [c for c in numeric_cols]\n",
    "\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"No numeric features found after excluding leakage. Inspect df.columns\")\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[TARGET_COL].copy()\n",
    "\n",
    "print(\"Selected numeric features (count):\", len(features))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows with missing features/target. Remaining rows: 7324\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Missing values - either drop rows with NaNs or impute numeric features\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "if USE_IMPUTATION:\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
    "    X = X_imputed\n",
    "    print(\"Imputation applied (mean) to numeric features.\")\n",
    "else:\n",
    "    mask = X.notna().all(axis=1) & (~y.isna())\n",
    "    X = X.loc[mask]\n",
    "    y = y.loc[mask]\n",
    "    print(\"Dropped rows with missing features/target. Remaining rows:\", len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-aware split used (timestamp). Train: 5493, Test: 1831\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Train-test split (time-aware if timestamp exists, otherwise random)\n",
    "time_col = None\n",
    "for name in TIME_COL_NAMES:\n",
    "    if name in df.columns:\n",
    "        time_col = name\n",
    "        break\n",
    "\n",
    "if time_col:\n",
    "    # align indices and sort by time\n",
    "    idx = X.index\n",
    "    tmp = df.loc[idx, :].copy()\n",
    "    tmp[time_col] = pd.to_datetime(tmp[time_col])\n",
    "    tmp = tmp.sort_values(by=time_col)\n",
    "    X = X.loc[tmp.index]\n",
    "    y = y.loc[tmp.index]\n",
    "    split_idx = int((1 - TEST_SIZE) * len(X))\n",
    "    X_train = X.iloc[:split_idx]\n",
    "    X_test  = X.iloc[split_idx:]\n",
    "    y_train = y.iloc[:split_idx]\n",
    "    y_test  = y.iloc[split_idx:]\n",
    "    print(f\"Time-aware split used ({time_col}). Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE,\n",
    "                                                        random_state=RANDOM_STATE, shuffle=True)\n",
    "    print(f\"Random split used. Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling complete. Feature count: 11\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Scaling (fit scaler on train only)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled  = pd.DataFrame(scaler.transform(X_test),  columns=X_test.columns,  index=X_test.index)\n",
    "feature_names = list(X_train.columns)\n",
    "print(\"Scaling complete. Feature count:\", len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models defined: ['LinearRegression', 'Ridge', 'Lasso', 'SVR_rbf', 'RandomForest', 'GradientBoosting', 'AdaBoost', 'KNeighbors', 'MLP']\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Define the models dictionary (core models)\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=RANDOM_STATE),\n",
    "    \"Lasso\": Lasso(alpha=0.01, random_state=RANDOM_STATE, max_iter=5000),\n",
    "    \"SVR_rbf\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, random_state=RANDOM_STATE),\n",
    "    \"AdaBoost\": AdaBoostRegressor(n_estimators=200, random_state=RANDOM_STATE),\n",
    "    \"KNeighbors\": KNeighborsRegressor(n_neighbors=7),\n",
    "    \"MLP\": MLPRegressor(hidden_layer_sizes=(128,64), max_iter=1000, early_stopping=True, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "if XGBRegressor is not None:\n",
    "    models[\"XGBoost\"] = XGBRegressor(n_estimators=300, learning_rate=0.05, random_state=RANDOM_STATE, verbosity=0)\n",
    "if LGBMRegressor is not None:\n",
    "    models[\"LightGBM\"] = LGBMRegressor(n_estimators=300, learning_rate=0.05, random_state=RANDOM_STATE)\n",
    "if CatBoostRegressor is not None:\n",
    "    models[\"CatBoost\"] = CatBoostRegressor(iterations=500, learning_rate=0.05, verbose=0, random_seed=RANDOM_STATE)\n",
    "\n",
    "print(\"Models defined:\", list(models.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after cleaning: (5481, 11) (5481,)\n",
      "Test shape after cleaning: (1806, 11) (1806,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Clean target (y_train, y_test) -> remove '-' and force numeric\n",
    "y_train = pd.to_numeric(y_train.replace(\"-\", np.nan), errors=\"coerce\")\n",
    "y_test  = pd.to_numeric(y_test.replace(\"-\", np.nan), errors=\"coerce\")\n",
    "\n",
    "# 2) Replace '-' in X and force numeric where possible\n",
    "X_train = X_train.replace(\"-\", np.nan)\n",
    "X_test  = X_test.replace(\"-\", np.nan)\n",
    "\n",
    "# If you have obvious non-numeric columns like 'timestamp', drop them here\n",
    "for col in [\"timestamp\"]:\n",
    "    if col in X_train.columns:\n",
    "        X_train = X_train.drop(columns=[col])\n",
    "        X_test  = X_test.drop(columns=[col])\n",
    "\n",
    "# Keep only numeric columns\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "X_train = X_train[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "X_test  = X_test[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# 3) Drop rows with NaNs in TRAIN\n",
    "mask_train = (~X_train.isna().any(axis=1)) & (~y_train.isna())\n",
    "X_train = X_train[mask_train]\n",
    "y_train = y_train[mask_train]\n",
    "\n",
    "# 4) Drop rows with NaNs in TEST\n",
    "mask_test = (~X_test.isna().any(axis=1)) & (~y_test.isna())\n",
    "X_test = X_test[mask_test]\n",
    "y_test = y_test[mask_test]\n",
    "\n",
    "print(\"Train shape after cleaning:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape after cleaning:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    index=X_train.index,\n",
    "    columns=X_train.columns\n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    index=X_test.index,\n",
    "    columns=X_test.columns\n",
    ")\n",
    "\n",
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LinearRegression ---\n",
      "LinearRegression | r2_test: 0.1479 rmse_test: 83.0358 cv_r2: 0.8626 ± 0.0122\n",
      "\n",
      "--- Ridge ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge | r2_test: 0.1493 rmse_test: 82.9641 cv_r2: 0.8626 ± 0.0122\n",
      "\n",
      "--- Lasso ---\n",
      "Lasso | r2_test: 0.1518 rmse_test: 82.8436 cv_r2: 0.8626 ± 0.0122\n",
      "\n",
      "--- SVR_rbf ---\n",
      "SVR_rbf | r2_test: 0.0045 rmse_test: 89.7499 cv_r2: 0.7817 ± 0.0494\n",
      "\n",
      "--- RandomForest ---\n",
      "RandomForest | r2_test: 0.3825 rmse_test: 70.6862 cv_r2: 0.9973 ± 0.0043\n",
      "\n",
      "--- GradientBoosting ---\n",
      "GradientBoosting | r2_test: 0.3542 rmse_test: 72.2844 cv_r2: 0.9991 ± 0.0011\n",
      "\n",
      "--- AdaBoost ---\n",
      "AdaBoost | r2_test: 0.3340 rmse_test: 73.4081 cv_r2: 0.9688 ± 0.0026\n",
      "\n",
      "--- KNeighbors ---\n",
      "KNeighbors | r2_test: -0.3545 rmse_test: 104.6901 cv_r2: 0.7980 ± 0.0065\n",
      "\n",
      "--- MLP ---\n",
      "MLP | r2_test: 0.4454 rmse_test: 66.9883 cv_r2: 0.9973 ± 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Training loop (CV on train, fit final model, predict on test, compute importances)\n",
    "results = []\n",
    "preds_long = []\n",
    "importances_list = []\n",
    "KFOLD = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    try:\n",
    "        tree_like = name in (\"RandomForest\", \"GradientBoosting\", \"AdaBoost\", \"XGBoost\", \"LightGBM\", \"CatBoost\")\n",
    "        if tree_like:\n",
    "            Xtr = X_train.values\n",
    "            Xte = X_test.values\n",
    "        else:\n",
    "            Xtr = X_train_scaled.values\n",
    "            Xte = X_test_scaled.values\n",
    "\n",
    "        # Cross-validation on training set (helps detect overfitting)\n",
    "        try:\n",
    "            cv_scores = cross_val_score(model, Xtr, y_train.values, cv=KFOLD, scoring=\"r2\", n_jobs=-1)\n",
    "            cv_mean = float(np.mean(cv_scores))\n",
    "            cv_std = float(np.std(cv_scores))\n",
    "        except Exception as e:\n",
    "            print(\"CV failed:\", e)\n",
    "            cv_mean = np.nan\n",
    "            cv_std = np.nan\n",
    "\n",
    "        # Fit on full training set\n",
    "        model.fit(Xtr, y_train)\n",
    "\n",
    "        # Predict on test\n",
    "        y_pred = model.predict(Xte)\n",
    "\n",
    "        # Metrics\n",
    "        r2 = float(r2_score(y_test, y_pred))\n",
    "        mse = float(mean_squared_error(y_test, y_pred))\n",
    "        rmse = float(np.sqrt(mse))\n",
    "\n",
    "        # Record per-sample predictions\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"model\": name,\n",
    "            \"sample_index\": X_test.index.astype(str),\n",
    "            \"y_true\": y_test.values,\n",
    "            \"y_pred\": y_pred\n",
    "        })\n",
    "        preds_long.append(temp_df)\n",
    "\n",
    "        # Feature importances (coef_, feature_importances_, or permutation)\n",
    "        try:\n",
    "            if hasattr(model, \"coef_\"):\n",
    "                coef = np.asarray(model.coef_).ravel()\n",
    "                imp_df = pd.DataFrame({\"feature\": feature_names, \"importance\": coef})\n",
    "            elif hasattr(model, \"feature_importances_\"):\n",
    "                fi = np.asarray(model.feature_importances_).ravel()\n",
    "                imp_df = pd.DataFrame({\"feature\": feature_names, \"importance\": fi})\n",
    "            else:\n",
    "                perm = permutation_importance(model, Xte, y_test, n_repeats=PERM_N_REPEATS, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "                imp_df = pd.DataFrame({\"feature\": feature_names, \"importance\": perm.importances_mean})\n",
    "        except Exception as e:\n",
    "            print(\"Importance extraction failed:\", e)\n",
    "            imp_df = pd.DataFrame({\"feature\": feature_names, \"importance\": [np.nan]*len(feature_names)})\n",
    "\n",
    "        imp_df[\"model\"] = name\n",
    "        importances_list.append(imp_df[[\"model\",\"feature\",\"importance\"]])\n",
    "\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"r2_test\": r2,\n",
    "            \"rmse_test\": rmse,\n",
    "            \"cv_r2_mean\": cv_mean,\n",
    "            \"cv_r2_std\": cv_std\n",
    "        })\n",
    "\n",
    "        print(f\"{name} | r2_test: {r2:.4f} rmse_test: {rmse:.4f} cv_r2: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Model {name} FAILED: {e}\")\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"r2_test\": np.nan,\n",
    "            \"rmse_test\": np.nan,\n",
    "            \"cv_r2_mean\": np.nan,\n",
    "            \"cv_r2_std\": np.nan\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined results to: ../asset/prediction/model_predictions_metrics.csv\n",
      "Also saved: model_metrics_table.csv, test_predictions_by_model_long.csv, feature_importances_long.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Assemble outputs and save CSVs to assets/\n",
    "metrics_df = pd.DataFrame(results).sort_values(by=\"r2_test\", ascending=False).reset_index(drop=True)\n",
    "preds_all_df = pd.concat(preds_long, ignore_index=True) if preds_long else pd.DataFrame(columns=[\"model\",\"sample_index\",\"y_true\",\"y_pred\"])\n",
    "importances_df = pd.concat(importances_list, ignore_index=True) if importances_list else pd.DataFrame(columns=[\"model\",\"feature\",\"importance\"])\n",
    "\n",
    "# Construct combined single-file output (metrics rows then prediction rows)\n",
    "metrics_rows = metrics_df.copy()\n",
    "metrics_rows[\"row_type\"] = \"metric\"\n",
    "metrics_rows[\"sample_index\"] = \"\"\n",
    "# ensure metric columns exist\n",
    "metrics_rows = metrics_rows.rename(columns={\"r2_test\":\"r2\",\"rmse_test\":\"rmse\"})\n",
    "for c in [\"y_true\",\"y_pred\",\"cv_r2_mean\",\"cv_r2_std\"]:\n",
    "    if c not in metrics_rows.columns:\n",
    "        metrics_rows[c] = \"\"\n",
    "\n",
    "predictions_out = preds_all_df.copy()\n",
    "predictions_out[\"row_type\"] = \"prediction\"\n",
    "# ensure metric columns present but empty in prediction rows\n",
    "for c in [\"r2\",\"rmse\",\"cv_r2_mean\",\"cv_r2_std\"]:\n",
    "    predictions_out[c] = \"\"\n",
    "\n",
    "# Align column order\n",
    "export_cols = [\"row_type\",\"model\",\"sample_index\",\"y_true\",\"y_pred\",\"r2\",\"rmse\",\"cv_r2_mean\",\"cv_r2_std\"]\n",
    "final_combined = pd.concat([metrics_rows[export_cols], predictions_out[export_cols]], ignore_index=True)\n",
    "\n",
    "OUT_PATH = os.path.join(ASSETS_PATH, \"model_predictions_metrics.csv\")\n",
    "final_combined.to_csv(OUT_PATH, index=False)\n",
    "metrics_df.to_csv(os.path.join(ASSETS_PATH, \"model_metrics_table.csv\"), index=False)\n",
    "preds_all_df.to_csv(os.path.join(ASSETS_PATH, \"test_predictions_by_model_long.csv\"), index=False)\n",
    "importances_df.to_csv(os.path.join(ASSETS_PATH, \"feature_importances_long.csv\"), index=False)\n",
    "\n",
    "print(\"Saved combined results to:\", OUT_PATH)\n",
    "print(\"Also saved: model_metrics_table.csv, test_predictions_by_model_long.csv, feature_importances_long.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>r2_test</th>\n",
       "      <th>rmse_test</th>\n",
       "      <th>cv_r2_mean</th>\n",
       "      <th>cv_r2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>66.988286</td>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.382479</td>\n",
       "      <td>70.686249</td>\n",
       "      <td>0.997294</td>\n",
       "      <td>0.004298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.354239</td>\n",
       "      <td>72.284433</td>\n",
       "      <td>0.999073</td>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.334007</td>\n",
       "      <td>73.408092</td>\n",
       "      <td>0.968848</td>\n",
       "      <td>0.002560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.151797</td>\n",
       "      <td>82.843581</td>\n",
       "      <td>0.862639</td>\n",
       "      <td>0.012196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.149326</td>\n",
       "      <td>82.964143</td>\n",
       "      <td>0.862635</td>\n",
       "      <td>0.012191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.147856</td>\n",
       "      <td>83.035824</td>\n",
       "      <td>0.862628</td>\n",
       "      <td>0.012245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR_rbf</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>89.749890</td>\n",
       "      <td>0.781669</td>\n",
       "      <td>0.049422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>-0.354545</td>\n",
       "      <td>104.690130</td>\n",
       "      <td>0.798007</td>\n",
       "      <td>0.006514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model   r2_test   rmse_test  cv_r2_mean  cv_r2_std\n",
       "0               MLP  0.445400   66.988286    0.997327   0.000334\n",
       "1      RandomForest  0.382479   70.686249    0.997294   0.004298\n",
       "2  GradientBoosting  0.354239   72.284433    0.999073   0.001076\n",
       "3          AdaBoost  0.334007   73.408092    0.968848   0.002560\n",
       "4             Lasso  0.151797   82.843581    0.862639   0.012196\n",
       "5             Ridge  0.149326   82.964143    0.862635   0.012191\n",
       "6  LinearRegression  0.147856   83.035824    0.862628   0.012245\n",
       "7           SVR_rbf  0.004480   89.749890    0.781669   0.049422\n",
       "8        KNeighbors -0.354545  104.690130    0.798007   0.006514"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>sample_index</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7357</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.043885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7358</td>\n",
       "      <td>38.0</td>\n",
       "      <td>51.371611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7359</td>\n",
       "      <td>87.0</td>\n",
       "      <td>73.985199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7360</td>\n",
       "      <td>83.0</td>\n",
       "      <td>75.943895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7361</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.263250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7362</td>\n",
       "      <td>128.0</td>\n",
       "      <td>102.827856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7363</td>\n",
       "      <td>73.0</td>\n",
       "      <td>63.511652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7364</td>\n",
       "      <td>53.0</td>\n",
       "      <td>49.918251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7365</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.545911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7366</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.282143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7367</td>\n",
       "      <td>56.0</td>\n",
       "      <td>50.687705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>7368</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.003714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model sample_index  y_true      y_pred\n",
       "0   LinearRegression         7357    76.0   66.043885\n",
       "1   LinearRegression         7358    38.0   51.371611\n",
       "2   LinearRegression         7359    87.0   73.985199\n",
       "3   LinearRegression         7360    83.0   75.943895\n",
       "4   LinearRegression         7361    75.0   70.263250\n",
       "5   LinearRegression         7362   128.0  102.827856\n",
       "6   LinearRegression         7363    73.0   63.511652\n",
       "7   LinearRegression         7364    53.0   49.918251\n",
       "8   LinearRegression         7365    23.0   38.545911\n",
       "9   LinearRegression         7366    54.0   54.282143\n",
       "10  LinearRegression         7367    56.0   50.687705\n",
       "11  LinearRegression         7368    61.0   58.003714"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_all_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>latitude</td>\n",
       "      <td>-5.724093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>longitude</td>\n",
       "      <td>12.837533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>pm25_ugm3</td>\n",
       "      <td>45.247357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>co_ppm</td>\n",
       "      <td>-0.182084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>no2_ppb</td>\n",
       "      <td>2.273526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>so2_ppb</td>\n",
       "      <td>0.155375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>o3_ppb</td>\n",
       "      <td>1.105466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>temperature_c</td>\n",
       "      <td>0.686551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>relative_humidity</td>\n",
       "      <td>-0.304541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>wind_speed_ms</td>\n",
       "      <td>-0.667958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>wind_direction_deg</td>\n",
       "      <td>-0.412327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>latitude</td>\n",
       "      <td>-5.716241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model             feature  importance\n",
       "0   LinearRegression            latitude   -5.724093\n",
       "1   LinearRegression           longitude   12.837533\n",
       "2   LinearRegression           pm25_ugm3   45.247357\n",
       "3   LinearRegression              co_ppm   -0.182084\n",
       "4   LinearRegression             no2_ppb    2.273526\n",
       "5   LinearRegression             so2_ppb    0.155375\n",
       "6   LinearRegression              o3_ppb    1.105466\n",
       "7   LinearRegression       temperature_c    0.686551\n",
       "8   LinearRegression   relative_humidity   -0.304541\n",
       "9   LinearRegression       wind_speed_ms   -0.667958\n",
       "10  LinearRegression  wind_direction_deg   -0.412327\n",
       "11             Ridge            latitude   -5.716241"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances_df.head(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
